{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN imports\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = 'data/train/'\n",
    "test_img_path = 'data/test/'\n",
    "\n",
    "train_set = []\n",
    "for label in os.listdir(train_img_path):\n",
    "    if label == \".DS_Store\":\n",
    "        continue\n",
    "    for img in os.listdir(os.path.join(train_img_path, label)):\n",
    "        if img == \".DS_Store\":\n",
    "            continue\n",
    "        train_set.append((os.path.join(train_img_path, label, img), int(label)))\n",
    "\n",
    "test_set = []\n",
    "for label in os.listdir(test_img_path):\n",
    "    if label == \".DS_Store\":\n",
    "        continue\n",
    "    for img in os.listdir(os.path.join(test_img_path, label)):\n",
    "        if img == \".DS_Store\":\n",
    "            continue\n",
    "        test_set.append((os.path.join(test_img_path, label, img), int(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 57.42507815361023 seconds ---\n",
      "--- 13.50636076927185 seconds ---\n"
     ]
    }
   ],
   "source": [
    "train_imgs = []\n",
    "train_labels = []\n",
    "start_time = time.time()\n",
    "for img, label in train_set:\n",
    "    img = np.asarray(Image.open(img))\n",
    "    train_imgs.append(img)\n",
    "    train_labels.append(label)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  \n",
    "\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "start_time = time.time()\n",
    "for img, label in test_set:\n",
    "    img = np.asarray(Image.open(img))\n",
    "    test_imgs.append(img)\n",
    "    test_labels.append(label)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78240 samples, validate on 19560 samples\n",
      "Epoch 1/10\n",
      "78240/78240 [==============================] - 1933s 25ms/sample - loss: 2.9659 - accuracy: 0.1053 - val_loss: 2.7563 - val_accuracy: 0.1634\n",
      "Epoch 2/10\n",
      "78240/78240 [==============================] - 1738s 22ms/sample - loss: 2.3188 - accuracy: 0.3015 - val_loss: 1.8407 - val_accuracy: 0.4529\n",
      "Epoch 3/10\n",
      "78240/78240 [==============================] - 1724s 22ms/sample - loss: 1.5052 - accuracy: 0.5446 - val_loss: 1.4420 - val_accuracy: 0.5670\n",
      "Epoch 4/10\n",
      "78240/78240 [==============================] - 1727s 22ms/sample - loss: 1.0611 - accuracy: 0.6769 - val_loss: 1.3837 - val_accuracy: 0.6036\n",
      "Epoch 5/10\n",
      "78240/78240 [==============================] - 1740s 22ms/sample - loss: 0.7571 - accuracy: 0.7639 - val_loss: 1.5120 - val_accuracy: 0.5972\n",
      "Epoch 6/10\n",
      "78240/78240 [==============================] - 1730s 22ms/sample - loss: 0.5430 - accuracy: 0.8283 - val_loss: 1.6307 - val_accuracy: 0.6198\n",
      "Epoch 7/10\n",
      "78240/78240 [==============================] - 1747s 22ms/sample - loss: 0.4136 - accuracy: 0.8671 - val_loss: 2.0830 - val_accuracy: 0.5840\n",
      "Epoch 8/10\n",
      "78240/78240 [==============================] - 1745s 22ms/sample - loss: 0.3303 - accuracy: 0.8942 - val_loss: 2.5362 - val_accuracy: 0.5771\n",
      "Epoch 9/10\n",
      "78240/78240 [==============================] - 1748s 22ms/sample - loss: 0.2968 - accuracy: 0.9066 - val_loss: 2.7650 - val_accuracy: 0.5777\n",
      "Epoch 10/10\n",
      "78240/78240 [==============================] - 1748s 22ms/sample - loss: 0.2603 - accuracy: 0.9187 - val_loss: 2.8356 - val_accuracy: 0.5886\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(22, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(np.array(train_imgs), np.array(train_labels), epochs=10, shuffle=True, validation_data=(np.array(test_imgs), np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Xception pretrained model:\n",
    "In this model we use a pretrained model to find the features, and then add a 3 layer CNN on top of that model as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionBottleneck(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(XceptionBottleneck, self).__init__()\n",
    "        \n",
    "        # Define xception layer (include_top=False and use imagenet weights), \n",
    "        # see: https://keras.io/applications/#models-for-image-classification-with-weights-trained-on-imagenet\n",
    "        self.xception_layers = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "        \n",
    "        # Define pooling GlobalAveragePooling2D \n",
    "        # see: https://keras.io/layers/pooling/  \n",
    "        self.pooling_layer = GlobalAveragePooling2D()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        result = self.xception_layers(inputs)\n",
    "        result = self.pooling_layer(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottleneck_layers(numpy_data, batch_size, device):\n",
    "    \n",
    "    bottle_necks = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(numpy_data).batch(batch_size)\n",
    "    n_samples = numpy_data.shape[0]\n",
    "\n",
    "    with tf.device(device):\n",
    "        xception_out = XceptionBottleneck()\n",
    "        for batch_num, image in enumerate(dataset):\n",
    "            print('\\rComputing bottle neck layers... batch {} of {}'.format(batch_num+1, n_samples//batch_size), end=\"\")\n",
    "            \n",
    "            result = xception_out(image)\n",
    "            result = result.numpy()\n",
    "            bottle_necks.append(result)\n",
    "            \n",
    "    return np.vstack(bottle_necks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bottle neck layers... batch 1565 of 1564--- 2872.5276679992676 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# device = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\n",
    "device = \"cpu:0\"\n",
    "bottle_necks = cache_bottleneck_layers(np.array(train_imgs, dtype=np.float32), batch_size=50, device=device)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = \"./cache/\"\n",
    "fname = 'bottle_neck_train.npz'\n",
    "train_save_path = os.path.join(cache_path, fname)\n",
    "\n",
    "if not os.path.isdir(cache_path): \n",
    "    os.mkdir(cache_path)\n",
    "    \n",
    "np.savez(train_save_path, bottle_necks=bottle_necks, labels=np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bottle neck layers... batch 392 of 391--- 638.8322191238403 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# device = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\n",
    "device = \"cpu:0\"\n",
    "bottle_necks = cache_bottleneck_layers(np.array(test_imgs, dtype=np.float32), batch_size=50, device=device)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = \"./cache/\"\n",
    "fname = 'bottle_neck_test.npz'\n",
    "test_save_path = os.path.join(cache_path, fname)\n",
    "\n",
    "if not os.path.isdir(cache_path): \n",
    "    os.mkdir(cache_path)\n",
    "    \n",
    "np.savez(test_save_path, bottle_necks=bottle_necks, labels=np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super(XceptionClassifier, self).__init__()\n",
    "        # Define the layer(s) you would like to use for your classifier\n",
    "        self.dense_layer_1 = tf.keras.layers.Dense(units=20*n_classes, activation=tf.keras.activations.relu)\n",
    "        self.dense_layer_2 = tf.keras.layers.Dense(units=5*n_classes, activation=tf.keras.activations.relu)\n",
    "        self.dense_layer_3 = tf.keras.layers.Dense(units=n_classes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Set this up appropriately, will depend on how many layers you choose\n",
    "        result = self.dense_layer_1(inputs)\n",
    "        result = self.dense_layer_2(result)\n",
    "        result = self.dense_layer_3(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(train_save_path)\n",
    "train_bottle_necks, train_labels = data['bottle_necks'],  data['labels']\n",
    "\n",
    "data = np.load(test_save_path)\n",
    "test_bottle_necks, test_labels = data['bottle_necks'],  data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16        # You will play around with this \n",
    "n_epochs = 200         # Choose num epochs based on when you think the parameters have converged\n",
    "learning_rate = 0.00001 # You will try different learning rates\n",
    "\n",
    "train_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dataset = tf.data.Dataset.from_tensor_slices(train_bottle_necks)\n",
    "train_labels_dataset = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "train_dataset = tf.data.Dataset.zip((train_images_dataset, train_labels_dataset))\n",
    "train_dataset = train_dataset.batch(batch_size).shuffle(buffer_size=train_bottle_necks.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_classifier = XceptionClassifier(n_classes=22)\n",
    "optimizer = tf.optimizers.Adam(learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199, Batch: 4880, Loss: 0.1278851181268692737--- 21690.22667312622 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with tf.device(device):\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch, (images, labels) in enumerate(train_dataset):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Compute logits\n",
    "                logits = x_classifier(images)\n",
    "                xe_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "                \n",
    "            train_loss_history.append(xe_loss.numpy())\n",
    "            # Compute gradient and apply gradients\n",
    "            grads = tape.gradient(xe_loss, x_classifier.variables)\n",
    "            optimizer.apply_gradients(zip(grads, x_classifier.variables))\n",
    "#                                       , global_step=tf.compat.v1.train.get_or_create_global_step())\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print('\\rEpoch: {}, Batch: {}, Loss: {}'.format(epoch, batch, train_loss_history[-1]), end='')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9116180981595092 0.5053680981595092\n"
     ]
    }
   ],
   "source": [
    "## computing the train accuracy for first model\n",
    "logits = x_classifier(tf.constant(train_bottle_necks))\n",
    "y_pred = tf.nn.softmax(logits).numpy()\n",
    "train_pred = np.argmax(y_pred, axis=1)\n",
    "train_accuracy = np.sum(train_pred == train_labels) / len(train_pred)\n",
    "\n",
    "## computing the validation accuracy for first model\n",
    "logits = x_classifier(tf.constant(test_bottle_necks))\n",
    "y_pred = tf.nn.softmax(logits).numpy()\n",
    "test_pred = np.argmax(y_pred, axis=1)\n",
    "test_accuracy = np.sum(test_pred == test_labels) / len(test_pred)\n",
    "\n",
    "print(train_accuracy, test_accuracy)\n",
    "# .... complete parts (e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Batch: 4880, Loss: 0.908546507358551--- 4780.221822977066 seconds ---\n"
     ]
    }
   ],
   "source": [
    "x_classifier_100 = XceptionClassifier(n_classes=20)\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "n_epochs = 100\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.device(device):\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch, (images, labels) in enumerate(train_dataset):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Compute logits\n",
    "                logits = x_classifier_100(images)\n",
    "                xe_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "                \n",
    "            train_loss_history.append(xe_loss.numpy())\n",
    "            # Compute gradient and apply gradients\n",
    "            grads = tape.gradient(xe_loss, x_classifier_100.variables)\n",
    "            optimizer.apply_gradients(zip(grads, x_classifier_100.variables))\n",
    "#                                       , global_step=tf.compat.v1.train.get_or_create_global_step())\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print('\\rEpoch: {}, Batch: {}, Loss: {}'.format(epoch, batch, train_loss_history[-1]), end='')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7262525562372188 0.4947852760736196\n"
     ]
    }
   ],
   "source": [
    "## computing the train accuracy for first model\n",
    "logits = x_classifier_100(tf.constant(train_bottle_necks))\n",
    "y_pred = tf.nn.softmax(logits).numpy()\n",
    "train_pred = np.argmax(y_pred, axis=1)\n",
    "train_accuracy = np.sum(train_pred == train_labels) / len(train_pred)\n",
    "\n",
    "## computing the validation accuracy for first model\n",
    "logits = x_classifier_100(tf.constant(test_bottle_necks))\n",
    "y_pred = tf.nn.softmax(logits).numpy()\n",
    "test_pred = np.argmax(y_pred, axis=1)\n",
    "test_accuracy = np.sum(test_pred == test_labels) / len(test_pred)\n",
    "\n",
    "print(train_accuracy, test_accuracy)\n",
    "# .... complete parts (e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
